name: Sync Datasets to Azure Blob Storage

on:
  workflow_dispatch:

env:
  STORAGE_ACCOUNT_NAME: ${{ secrets.STORAGE_ACCOUNT_NAME }}
  STORAGE_CONTAINER_NAME: datasets
  STORAGE_SAS_TOKEN: "?${{ secrets.STORAGE_SAS_TOKEN }}"

jobs:
  sync-and-trigger:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: write
      id-token: write

    steps:
    - name: Checkout repo
      uses: actions/checkout@v4

    - name: Install AzCopy
      run: |
        curl -sL https://aka.ms/downloadazcopy-v10-linux | tar -xz
        sudo cp ./azcopy_linux_amd64_*/azcopy /usr/bin/

    - name: List blobs using curl and Upload and trigger training for new datasets
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        REPO_NAME: ${{ github.repository }}
      run: |
        echo "üì• Listando blobs remotos desde Azure Blob Storage..."
        curl -s "https://${{ env.STORAGE_ACCOUNT_NAME }}.blob.core.windows.net/${{ env.STORAGE_CONTAINER_NAME }}?restype=container&comp=list&${{ env.STORAGE_SAS_TOKEN }}" \
        | tr '>' '>\n' | grep "<Name>" | awk -F'[<>]' '{print $3}' > remote_basenames.txt

        echo "üìÑ Contenido de remote_basenames.txt:"
        cat -A remote_basenames.txt || echo "‚ùå No existe"

        if [[ ! -s remote_basenames.txt ]]; then
          echo "‚ö†Ô∏è remote_basenames.txt est√° vac√≠o, se subir√°n todos los archivos locales"
          touch remote_basenames.txt
        fi

        for file in ./data/*.jsonl; do
          if [[ -f "$file" ]]; then
            filename=$(basename "$file")
            echo "üîç Checking $filename..."
            
            if ! grep -Fx -- "$filename" <(tr -d '\r' < remote_basenames.txt); then
              echo "‚¨ÜÔ∏è Uploading $filename..."
              azcopy copy "$file" \
                "https://${{ env.STORAGE_ACCOUNT_NAME }}.blob.core.windows.net/${{ env.STORAGE_CONTAINER_NAME }}/$filename?${{ env.STORAGE_SAS_TOKEN }}" \
                --overwrite=false

              if [ $? -eq 0 ]; then
                echo "‚úÖ Successfully uploaded $filename"
                echo "üöÄ Triggering Azure ML training with $filename..."
                gh workflow run mlflow_train.yml \
                  --repo "$REPO_NAME" \
                  --field BLOB_DATASET_FILENAME="$filename"
              else
                echo "‚ùå Failed to upload $filename"
              fi
            else
              echo "‚è≠Ô∏è Skipping $filename (already uploaded)"
            fi
          fi
        done
