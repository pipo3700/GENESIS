name: Sync Datasets to Azure Blob Storage

on:
  workflow_dispatch:

env:
  STORAGE_ACCOUNT_NAME: ${{ secrets.STORAGE_ACCOUNT_NAME }}
  STORAGE_CONTAINER_NAME: datasets
  STORAGE_SAS_TOKEN: ${{ secrets.STORAGE_SAS_TOKEN }}

jobs:
  sync-and-trigger:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: write

    steps:
    - name: Checkout repo
      uses: actions/checkout@v4

    - name: Install AzCopy
      run: |
        curl -sL https://aka.ms/downloadazcopy-v10-linux | tar -xz
        sudo cp ./azcopy_linux_amd64_*/azcopy /usr/bin/

    - name: List files in Azure Blob Storage
      id: list_remote
      run: |
        azcopy list "https://${{ env.STORAGE_ACCOUNT_NAME }}.blob.core.windows.net/${{ env.STORAGE_CONTAINER_NAME }}?${{ env.STORAGE_SAS_TOKEN }}" --output-level quiet > remote_files.txt

    - name: Upload and trigger training for new datasets
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        REPO_NAME: ${{ github.repository }}
      run: |
        for file in ./data/*.jsonl; do
          filename=$(basename "$file")
          if ! grep -q "$filename" remote_files.txt; then
            echo "Uploading $filename..."
            azcopy copy "$file" \
              "https://${{ env.STORAGE_ACCOUNT_NAME }}.blob.core.windows.net/${{ env.STORAGE_CONTAINER_NAME }}/$filename?${{ env.STORAGE_SAS_TOKEN }}" \
              --overwrite=false

            echo "Triggering Azure ML training with $filename..."
            gh workflow run azureml_train_register.yml \
              --repo "$REPO_NAME" \
              --field BLOB_DATASET_FILENAME="$filename"
          else
            echo "Skipping $filename (already uploaded)"
          fi
        done
