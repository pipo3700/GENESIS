name: Sync Datasets to Azure Blob Storage

on:
  workflow_dispatch:

env:
  STORAGE_ACCOUNT_NAME: ${{ secrets.STORAGE_ACCOUNT_NAME }}
  STORAGE_CONTAINER_NAME: datasets
  STORAGE_SAS_TOKEN: ${{ secrets.STORAGE_SAS_TOKEN }}

jobs:
  sync-and-trigger:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: write
      id-token: write

    steps:
    - name: Checkout repo
      uses: actions/checkout@v4

    - name: Install AzCopy
      run: |
        curl -sL https://aka.ms/downloadazcopy-v10-linux | tar -xz
        sudo cp ./azcopy_linux_amd64_*/azcopy /usr/bin/

    - name: List blobs using curl and Upload and trigger training for new datasets
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        REPO_NAME: ${{ github.repository }}
      run: |
        echo "üì• Listando blobs remotos desde Azure Blob Storage..."

        curl_url="https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${STORAGE_CONTAINER_NAME}?restype=container&comp=list&${STORAGE_SAS_TOKEN}"
        echo "üåê URL: $curl_url"

        curl -s "$curl_url" > curl_output.xml
        echo "üìÑ Respuesta XML:"
        cat curl_output.xml

        # Extraer nombres de blobs
        tr '>' '>\n' < curl_output.xml | grep "<Name>" | awk -F'[<>]' '{print $3}' > remote_basenames.txt

        echo "üìÑ Contenido de remote_basenames.txt:"
        cat -A remote_basenames.txt || echo "‚ùå No existe o est√° vac√≠o"

        if [[ ! -s remote_basenames.txt ]]; then
          echo "‚ö†Ô∏è remote_basenames.txt est√° vac√≠o, se subir√°n todos los archivos locales"
          touch remote_basenames.txt
        fi

        for file in ./data/*.jsonl; do
          if [[ -f "$file" ]]; then
            filename=$(basename "$file")
            echo "üîç Checking $filename..."

            if ! grep -Fx -- "$filename" <(tr -d '\r' < remote_basenames.txt); then
              echo "‚¨ÜÔ∏è Subiendo $filename a Blob Storage..."
              azcopy copy "$file" \
                "https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${STORAGE_CONTAINER_NAME}/$filename?${STORAGE_SAS_TOKEN}" \
                --overwrite=false

              if [ $? -eq 0 ]; then
                echo "‚úÖ Upload exitoso de $filename"
                echo "üöÄ Ejecutando workflow de entrenamiento en Azure ML..."
                gh workflow run mlflow_train.yml \
                  --repo "$REPO_NAME" \
                  --field BLOB_DATASET_FILENAME="$filename"
              else
                echo "‚ùå Error al subir $filename con AzCopy"
              fi
            else
              echo "‚è≠Ô∏è Skipping $filename (ya existe en Blob)"
            fi
          fi
        done
